---
title: "Transformer model for language understanding"
author: "Athos Petri Damiani"
date: "05/01/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

This code is the translation from Python to R of the Transformer Tutorial implemented by Google. 

Original link:  [https://www.tensorflow.org/tutorials/text/transformer](https://www.tensorflow.org/tutorials/text/transformer)

[https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/text/transformer.ipynb#scrollTo=15VYkkSfKE3t](https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/text/transformer.ipynb#scrollTo=15VYkkSfKE3t)

```{r, message=FALSE, warning=FALSE}
library(keras)
library(tidyverse)
library(tensorflow)
library(tfdatasets)
library(zeallot)
library(reticulate)
library(assertthat)

# If not installed yet, installs tfds package and tfds module in Python.
# remotes::install_github("rstudio/tfds")
# tfds::install_tfds()
library(tfds)

# test 
# zeros <- tf$zeros(shape = c(4, 4))
# as.matrix(zeros)
vec_sub <- function(vector, start, end) {
  vector[start:(length(vector) + end + 1)]
}
```


## Setup input pipeline

```{r, message=FALSE, warning=FALSE}
examples <- tfds::tfds_load(name = 'ted_hrlr_translate/pt_to_en')
train_examples <- examples$train
val_examples <- examples$validation
```

Create a custom subwords tokenizer from the training dataset.

```{r}
# tokenizer_en <- train_examples %>%
#   tensorflow::iterate(function(x) x$en$numpy()) %>%
#   tfds$features$text$SubwordTextEncoder$build_from_corpus(2^13)
# # tokenizer_en$save_to_file("tokenizer_en")
tokenizer_en <- tfds$features$text$SubwordTextEncoder$load_from_file("tokenizer_en")
```

```{r}
# tokenizer_pt <- train_examples %>%
#   tensorflow::iterate(function(x) x$pt$numpy()) %>%
#   tfds$features$text$SubwordTextEncoder$build_from_corpus(2^13)
# # tokenizer_pt$save_to_file("tokenizer_pt")
tokenizer_pt <- tfds$features$text$SubwordTextEncoder$load_from_file("tokenizer_pt")
```

```{r}
sample_string = 'Transformer is awesome.'
tokenized_string <- tokenizer_en$encode(sample_string)
paste('Tokenized string is ', paste(tokenized_string, collapse = " "))

original_string <- tokenizer_en$decode(tokenized_string)
paste('The original string: ', original_string)
```

```{r}
walk(tokenized_string, ~ print(sprintf("%s ------> %s", .x, tokenizer_en$decode(c(.x, 0L)))))
```

```{r}
BUFFER_SIZE = 20000L
BATCH_SIZE = 16L
```

```{r}
MAX_LENGTH = 40L
```

```{r}
train_examples_iterator <- train_examples %>%
  dataset_batch(10e6) %>%
  reticulate::as_iterator()
```

```{r}
data_prep <- function(dataset) {
  # encode -------------------------------------------
  dataset_tbl <- tibble(
    lang = names(dataset$element_spec),
    text = dataset %>% tfdatasets::dataset_collect() %>% transpose(),
    tokenizer = list(tokenizer_en, tokenizer_pt)
  ) %>%
    mutate(
      tokens = map2(text, tokenizer, ~{
        vocab_size <- .y$vocab_size
        tkns <- .x %>% map(~.x$numpy()) %>% map(as.character) %>% map(.y$encode) 
        tkns %>% map(~{
          a <- c(vocab_size, .x, vocab_size +1) %>% as.integer()
          return(a)
        })
      }) %>% set_names(lang),
      length = map(tokens, ~.x %>% map_dbl(length))
    )
  
  # filter predicate ----------------------------------------
  is_smaller_than_max_length <- function(dataset) {
    dataset$length %>% transpose() %>% map_lgl(~all(unlist(.x) <= MAX_LENGTH))
  }
  
  # filter, reshape and coerse to tfdataset ---------------------------------
  final_dataset <- dataset_tbl$tokens %>% 
    transpose() %>% 
    keep(is_smaller_than_max_length(dataset_tbl)) %>% 
    transpose() %>%
    map(~{
      .x %>% 
        map(`length<-`, MAX_LENGTH) %>% 
        do.call(rbind, .) %>% 
        as.matrix() %>% 
        coalesce(0L) %>% 
        tf$convert_to_tensor(dtype = tf$int64)
    }) %>% 
    tensor_slices_dataset() %>%
    dataset_shuffle(BUFFER_SIZE) %>%
    dataset_padded_batch(BATCH_SIZE, padded_shapes = dict(en = list(-1L), pt = list(-1L)))
  
  return(final_dataset)
}

train_dataset <- data_prep(train_examples) %>%
  dataset_cache() %>%
  dataset_prefetch(tf$data$experimental$AUTOTUNE)

val_dataset <- data_prep(val_examples)
```

```{r}
val_dataset_iterator <- val_dataset %>% as_iterator()
```

```{r}
val_batch <- val_dataset_iterator %>% iter_next()
val_batch$pt
val_batch$en
```

```{r}
vec_en <- val_batch$en[1,]$numpy() %>% as.integer()
vec_pt <- val_batch$pt[1,]$numpy() %>% as.integer()

vec_en[vec_en < vec_en[1] & vec_en > 0] %>% tokenizer_en$decode()
vec_pt[vec_pt < vec_pt[1] & vec_pt > 0] %>% tokenizer_pt$decode()

walk(vec_en[vec_en < vec_en[1] & vec_en > 0], ~ print(sprintf("%s ------> %s", .x, tokenizer_en$decode(c(.x, 0L)))))
```

## Positional encoding

```{r}
get_angles <- function(pos, i, d_model) {
  angle_rates = 1 / 10000^(2 * floor(i/2) / d_model)
  pos %*% angle_rates
}

positional_encoding <- function(position, d_model) {
  angle_rads = get_angles(matrix(rev(seq_len(position) - 1), ncol = 1),
                          matrix(seq_len(d_model) - 1, nrow = 1),
                          d_model)
  
  even_indices = seq_len(d_model) %% 2 == 0
  # apply sin to even indices in the array; 2i
  angle_rads[ , even_indices] <- sin(angle_rads[, even_indices])
  
  # apply cos to odd indices in the array; 2i+1
  angle_rads[, !even_indices] <- cos(angle_rads[, !even_indices])
  
  angle_rads_tensor <- tf$convert_to_tensor(angle_rads, dtype = tf$float32) %>% tf$reshape(as.integer(c(1, position, d_model)))
  
  angle_rads_tensor
}

```

```{r}
position = 50
d_model = 512
img_data <- positional_encoding(position, d_model)$numpy() 
dim(img_data) <- c(position, d_model)

img_data %>%
  as.data.frame() %>%
  rownames_to_column(var = "y") %>%
  gather(x, value, -y) %>%
  mutate(
    x = readr::parse_number(x),
    y = as.numeric(y),
    y = max(y) - y
  ) %>%
  ggplot(aes(x = x, y = y, fill = value)) +
  geom_tile() +
  scale_fill_gradient2(low = "#67001f",mid = "#f7f7f7", high = "#053061") +
  theme_minimal() +
  labs(x = "Depth", y = "Position")
```

## Masking

```{r}
create_padding_mask <- function(seq) {
  seq <- tf$cast(tf$math$equal(seq, 0L), tf$float32)
  # add extra dimensions to add the padding
  # to the attention logits.
  shape <- as.integer(seq$get_shape()$as_list())
  shape <- if(length(shape) == 1) c(1L, shape) else shape
  seq <- tf$reshape(seq, tuple(shape[1], 1L, 1L, shape[length(shape)]))
  return(seq)
}

# return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)
# 
x = tf$constant(list(list(7, 6, 0, 0, 1), list(1, 2, 3, 0, 0), list(0, 0, 0, 4, 5)))
create_padding_mask(x)
```

```{r}
create_look_ahead_mask <- function(size) {
  mask <- 1 - tf$linalg$band_part(tf$ones(tuple(size, size)), -1L, 0L)
  return(mask)  # (seq_len, seq_len)
}
```

```{r}
x = tf$random$uniform(tuple(1L, 3L))
temp = create_look_ahead_mask(x$shape[1])
temp
```

## Scaled dot product attention

```{r}
scaled_dot_product_attention <- function(q, k, v, mask) {
  # Calculate the attention weights.
  # q, k, v must have matching leading dimensions.
  # k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.
  # The mask has different shapes depending on its type(padding or look ahead) 
  # but it must be broadcastable for addition.
  # 
  # Args:
  #   q: query shape == (..., seq_len_q, depth)
  #   k: key shape == (..., seq_len_k, depth)
  #   v: value shape == (..., seq_len_v, depth_v)
  #   mask: Float tensor with shape broadcastable 
  #         to (..., seq_len_q, seq_len_k). Defaults to None.
  #   
  # Returns:
  #   output, attention_weights
  matmul_qk = tf$matmul(q, k, transpose_b = TRUE)  # (..., seq_len_q, seq_len_k)
  
  # scale matmul_qk
  dk = tf$cast(tf$shape(k)[-1], tf$float32)
  scaled_attention_logits = matmul_qk / tf$math$sqrt(dk)
  
  # add the mask to the scaled tensor.
  if(!is.null(mask))
    scaled_attention_logits = scaled_attention_logits + (mask * -1e9)  
  
  # softmax is normalized on the last axis (seq_len_k) so that the scores
  # add up to 1.
  attention_weights = tf$nn$softmax(scaled_attention_logits, axis = -1L)  # (..., seq_len_q, seq_len_k)
  
  output = tf$matmul(attention_weights, v)  # (..., seq_len_q, depth_v)
  
  return(list(output, attention_weights))
}
```

```{r}
print_out <- function(q, k, v) {
  c(temp_out, temp_attn) %<-% scaled_dot_product_attention(q, k, v, NULL)
  print('Attention weights are:')
  print(temp_attn)
  print('Output is:')
  print(temp_out)
}
```

```{r}
temp_k <- tf$constant(list(c(10,0,0),
                           c(0,10,0),
                           c(0,0,10),
                           c(0,0,10)), dtype = tf$float32)  # (4, 3)

temp_v <- tf$constant(list(c(   1,0),
                           c(  10,0),
                           c( 100,5),
                           c(1000,6)), dtype = tf$float32)  # (4, 2)

# This `query` aligns with the second `key`,
# so the second `value` is returned.
temp_q <- tf$constant(list(c(0, 10, 0)), dtype = tf$float32)  # (1, 3)
print_out(temp_q, temp_k, temp_v)
```

```{r}
# This query aligns with a repeated key (third and fourth), 
# so all associated values get averaged.
temp_q <- tf$constant(list(c(0, 0, 10)), dtype = tf$float32)  # (1, 3)
print_out(temp_q, temp_k, temp_v)
```

```{r}
# This query aligns equally with the first and second key, 
# so their values get averaged.
temp_q <- tf$constant(list(c(10, 10, 0)), dtype = tf$float32)  # (1, 3)
print_out(temp_q, temp_k, temp_v)
```

Pass all the queries together.

```{r}
temp_q <- tf$constant(list(c(0, 0, 10), c(0, 10, 0), c(10, 10, 0)), dtype = tf$float32)  # (3, 3)
print_out(temp_q, temp_k, temp_v)
```

## Multi-head attention

```{r}
MultiHeadAttention <- PyClass(
  classname = "MultiHeadAttention", 
  inherit = tf$keras$layers$Layer, 
  defs = list(
    
    ###
    `__init__` = function(self, d_model, num_heads) {
      super()$`__init__`()
      self$num_heads = num_heads
      self$d_model = d_model
      
      assertthat::assert_that(d_model %% self$num_heads == 0)
      
      self$depth = floor(d_model / self$num_heads)
      
      self$wq = tf$keras$layers$Dense(d_model)
      self$wk = tf$keras$layers$Dense(d_model)
      self$wv = tf$keras$layers$Dense(d_model)
      
      self$dense = tf$keras$layers$Dense(d_model)
      return(NULL)
    },
    
    ###
    split_heads = function(self, x, batch_size) {
      # """Split the last dimension into (num_heads, depth).
      # Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)
      # """
      x = tf$reshape(x, as.integer(c(batch_size$numpy(), -1L, self$num_heads, self$depth)))
      return(tf$transpose(x, perm = c(0L, 2L, 1L, 3L)))
    },
    
    ###
    call = function(self, v, k, q, mask) {
      batch_size = tf$shape(q)[1]
      q = self$wq(q)  # (batch_size, seq_len, d_model)
      k = self$wk(k)  # (batch_size, seq_len, d_model)
      v = self$wv(v)  # (batch_size, seq_len, d_model)
      
      q = self$split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)
      k = self$split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)
      v = self$split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)
      
      # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)
      # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)
      c(scaled_attention, attention_weights) %<-% scaled_dot_product_attention(q, k, v, mask)
      
      scaled_attention = tf$transpose(scaled_attention, perm = tuple(0L, 2L, 1L, 3L))  # (batch_size, seq_len_q, num_heads, depth)
      
      concat_attention = tf$reshape(scaled_attention, as.integer(c(batch_size$numpy(), -1L, self$d_model)))  # (batch_size, seq_len_q, d_model)
      
      output = self$dense(concat_attention)  # (batch_size, seq_len_q, d_model)
      
      return(list(output, attention_weights)) 
    }
  )
)
```

```{r}
temp_mha <- MultiHeadAttention(d_model = 512L, num_heads = 8L)
y <- tf$random$uniform(tuple(1L, 60L, 512L))  # (batch_size, encoder_sequence, d_model)
c(out, attn) %<-% temp_mha$call(y, k = y, q = y, mask = NULL)

out$get_shape()
attn$get_shape()
```

## Point wise feed forward network

```{r}
point_wise_feed_forward_network <- function(d_model, dff) {
  keras_model_sequential() %>%
    layer_dense(units = dff, activation = "relu") %>%
    layer_dense(units = d_model)
}
```

```{r}
sample_ffn <- point_wise_feed_forward_network(512L, 2048L)
sample_ffn(tf$random$uniform(tuple(64L, 50L, 512L)))$shape
```

## Encoder and decoder

### Encoder layer

```{r}
EncoderLayer <- PyClass(
  "EncoderLayer",
  inherit = tf$keras$layers$Layer,
  defs = list(
    
    ###
    `__init__` = function(self, d_model, num_heads, dff, rate = 0.1) {
      super()$`__init__`()
      self$mha = MultiHeadAttention(d_model, num_heads)
      self$ffn = point_wise_feed_forward_network(d_model, dff)
      
      self$layernorm1 = tf$keras$layers$LayerNormalization(epsilon = 1e-6)
      self$layernorm2 = tf$keras$layers$LayerNormalization(epsilon = 1e-6)
      
      self$dropout1 = tf$keras$layers$Dropout(rate)
      self$dropout2 = tf$keras$layers$Dropout(rate)
      
      return(NULL)
    },
    
    ###
    call = function(self, x, training, mask) {
      c(attn_output, .) %<-% self$mha$call(x, x, x, mask)  # (batch_size, input_seq_len, d_model)
      attn_output = self$dropout1(attn_output, training = training)
      out1 = self$layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)
      
      ffn_output = self$ffn(out1)  # (batch_size, input_seq_len, d_model)
      ffn_output = self$dropout2(ffn_output, training = training)
      out2 = self$layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)
      
      return(out2)
    }
  )
)
```

```{r}
sample_encoder_layer <- EncoderLayer(512, 8, 2048)

sample_encoder_layer_output = sample_encoder_layer$call(tf$random$uniform(tuple(64L, 43L, 512L)), FALSE, NULL)

sample_encoder_layer_output$shape  # (batch_size, input_seq_len, d_model)
```

### Decoder layer

```{r}
DecoderLayer <- PyClass(
  "DecoderLayer",
  inherit = tf$keras$layers$Layer,
  defs = list(
    
    ###
    `__init__` = function(self, d_model, num_heads, dff, rate = 0.1) {
      super()$`__init__`()
      self$mha1 = MultiHeadAttention(d_model, num_heads)
      self$mha2 = MultiHeadAttention(d_model, num_heads)
      
      self$ffn = point_wise_feed_forward_network(d_model, dff)
      
      self$layernorm1 = tf$keras$layers$LayerNormalization(epsilon=1e-6)
      self$layernorm2 = tf$keras$layers$LayerNormalization(epsilon=1e-6)
      self$layernorm3 = tf$keras$layers$LayerNormalization(epsilon=1e-6)
      
      self$dropout1 = tf$keras$layers$Dropout(rate)
      self$dropout2 = tf$keras$layers$Dropout(rate)
      self$dropout3 = tf$keras$layers$Dropout(rate)
      
      return(NULL)
    },
    
    ###
    call = function(self, x, enc_output, training, look_ahead_mask, padding_mask) {
      # enc_output.shape == (batch_size, input_seq_len, d_model)
      
      c(attn1, attn_weights_block1) %<-% self$mha1$call(x, x, x, look_ahead_mask)  # (batch_size, target_seq_len, d_model)
      attn1 = self$dropout1(attn1, training = training)
      out1 = self$layernorm1(attn1 + x)
      
      c(attn2, attn_weights_block2) %<-% self$mha2$call(enc_output, enc_output, out1, padding_mask)  # (batch_size, target_seq_len, d_model)
      attn2 = self$dropout2(attn2, training=training)
      out2 = self$layernorm2(attn2 + out1)  # (batch_size, target_seq_len, d_model)
      
      ffn_output = self$ffn(out2)  # (batch_size, target_seq_len, d_model)
      ffn_output = self$dropout3(ffn_output, training=training)
      out3 = self$layernorm3(ffn_output + out2)  # (batch_size, target_seq_len, d_model)
      
      return(list(out3, attn_weights_block1, attn_weights_block2))
    }
  ) 
)
```

```{r}
sample_decoder_layer <- DecoderLayer(512, 8, 2048)

c(sample_decoder_layer_output, ., .) %<-% sample_decoder_layer$call(
  tf$random$uniform(tuple(64L, 50L, 512L)), 
  sample_encoder_layer_output, 
  FALSE, 
  NULL, 
  NULL
)

sample_decoder_layer_output$shape  # (batch_size, target_seq_len, d_model)
```

### Encoder

```{r}
Encoder <- PyClass(
  "Encoder",
  inherit = tf$keras$layers$Layer,
  defs = list(
    
    ###
    `__init__` = function(self, num_layers, d_model, num_heads, dff, input_vocab_size, maximum_position_encoding, rate = 0.1) {
      super()$`__init__`()
      self$d_model = d_model
      self$num_layers = num_layers
      
      self$embedding = tf$keras$layers$Embedding(input_vocab_size, d_model)
      self$pos_encoding = positional_encoding(maximum_position_encoding, self$d_model)
      
      self$enc_layers = replicate(num_layers, EncoderLayer(d_model, num_heads, dff, rate))
      
      self$dropout = tf$keras$layers$Dropout(rate)
      
      return(NULL)
    },
    
    ###
    call = function(self, x, training, mask) {
      
      seq_len = tf$shape(x)[length(tf$shape(x)$numpy())]
      # adding embedding and position encoding$
      x = self$embedding(x)  # (batch_size, input_seq_len, d_model)
      x = x * tf$math$sqrt(tf$cast(self$d_model, tf$float32))
      x = x + self$pos_encoding[, 1:seq_len, ]
      
      x = self$dropout(x, training = training)
      
      enc_layers_iter <- iterate(self$enc_layers)
      for(i in seq_len(self$num_layers)) {
        x = enc_layers_iter[[i]]$call(x, training, mask)
      }
      
      return(x)  # (batch_size, input_seq_len, d_model)
    }
  )
)
```


```{r}
sample_encoder <- Encoder(
  num_layers = 2L, 
  d_model = 512L, 
  num_heads = 8L, 
  dff = 2048L, 
  input_vocab_size = 8500L,
  maximum_position_encoding = 10000L
)

temp_input <- tf$random$uniform(tuple(64L, 62L), dtype = tf$int64, minval = 0L, maxval = 200L)

sample_encoder_output <- sample_encoder$call(temp_input, training = FALSE, mask = NULL)

print(sample_encoder_output$shape)  # (batch_size, input_seq_len, d_model)
```

### Decoder

```{r}
Decoder <- PyClass(
  "Decoder",
  inherit = tf$keras$layers$Layer,
  defs = list(
    
    ###
    `__init__` = function(self, num_layers, d_model, num_heads, dff, target_vocab_size, maximum_position_encoding, rate = 0.1) {
      super()$`__init__`()
      
      self$d_model = d_model
      self$num_layers = num_layers
      
      self$embedding = tf$keras$layers$Embedding(target_vocab_size, d_model)
      self$pos_encoding = positional_encoding(maximum_position_encoding, d_model)
      
      self$dec_layers = replicate(num_layers, DecoderLayer(d_model, num_heads, dff, rate))
      
      self$dropout = tf$keras$layers$Dropout(rate)
      
      return(NULL)
    },
    
    ###
    call = function(self, x, enc_output, training, look_ahead_mask, padding_mask) {
      
      seq_len = tf$shape(x)[length(tf$shape(x)$numpy())]
      attention_weights = list()
      
      x = self$embedding(x)  # (batch_size, target_seq_len, d_model)
      x = x * tf$math$sqrt(tf$cast(self$d_model, tf$float32))
      x = x + self$pos_encoding[, 1:seq_len, ]
      
      x = self$dropout(x, training=training)
      
      decs_layer_iter <- iterate(self$dec_layers)
      for(i in seq_len(self$num_layers)) {
        c(x, block1, block2) %<-% decs_layer_iter[[i]]$call(x, enc_output, training, look_ahead_mask, padding_mask)
        attention_weights[[sprintf('decoder_layer%s_block1', i+1)]] <- block1
        attention_weights[[sprintf('decoder_layer%s_block2', i+1)]] <- block2
      }
      
      # x$shape == (batch_size, target_seq_len, d_model)
      return(list(x, attention_weights))
    }
  )
)
```

```{r}
sample_decoder <- Decoder(
  num_layers = 2L, 
  d_model = 512L, 
  num_heads = 8L, 
  dff = 2048L, 
  target_vocab_size = 8000L,
  maximum_position_encoding = 5000L
)

temp_input <- tf$random$uniform(tuple(64L, 26L), dtype = tf$int64, minval = 0L, maxval = 200L)

c(output, attn) %<-% sample_decoder$call(
  temp_input, 
  enc_output = sample_encoder_output, 
  training = FALSE,
  look_ahead_mask = NULL, 
  padding_mask = NULL
)

output$shape
attn[['decoder_layer2_block2']]$shape
```

## Create the Transformer

```{r}
Transformer <- PyClass(
  "Transformer",
  inherit = tf$keras$Model,
  defs = list(
    
    ###
    `__init__` = function(self, num_layers, d_model, num_heads, dff, input_vocab_size, target_vocab_size, pe_input, pe_target, rate = 0.1) {
      super()$`__init__`()
      self$encoder = Encoder(num_layers, d_model, num_heads, dff, input_vocab_size, pe_input, rate)
      
      self$decoder = Decoder(num_layers, d_model, num_heads, dff, target_vocab_size, pe_target, rate)
      
      self$final_layer = tf$keras$layers$Dense(target_vocab_size)
      
      return(NULL)
    },
    
    ###
    call = function(self, inp, tar, training, enc_padding_mask, look_ahead_mask, dec_padding_mask) {
      enc_output = self$encoder$call(inp, training, enc_padding_mask)  # (batch_size, inp_seq_len, d_model)
      
      # dec_output$shape == (batch_size, tar_seq_len, d_model)
      c(dec_output, attention_weights) %<-% self$decoder$call(tar, enc_output, training, look_ahead_mask, dec_padding_mask)
      
      final_output = self$final_layer(dec_output)  # (batch_size, tar_seq_len, target_vocab_size)
      
      return(list(final_output, attention_weights))
    }
  )
)
```

```{r}
sample_transformer <- Transformer(
  num_layers = 2L, 
  d_model = 512L, 
  num_heads = 8L, 
  dff = 2048L, 
  input_vocab_size = 8500L, 
  target_vocab_size = 8000L, 
  pe_input = 10000L, 
  pe_target = 6000L
)

temp_input <- tf$random$uniform(tuple(64L, 38L), dtype = tf$int64, minval = 0L, maxval = 200L)
temp_target <- tf$random$uniform(tuple(64L, 36L), dtype = tf$int64, minval = 0L, maxval = 200L)

c(fn_out, .) %<-% sample_transformer$call(
  temp_input, 
  temp_target, 
  training = FALSE, 
  enc_padding_mask = NULL, 
  look_ahead_mask = NULL,
  dec_padding_mask = NULL
)

fn_out$shape  # (batch_size, tar_seq_len, target_vocab_size)
```

## Set hyperparameters

```{r}
num_layers = 4L
d_model = 128L
dff = 512L
num_heads = 8L

input_vocab_size = tokenizer_pt$vocab_size + 2L
target_vocab_size = tokenizer_en$vocab_size + 2L
dropout_rate = 0.1
```

## Optimizer

```{r}
CustomSchedule <- PyClass(
  "CustomSchedule",
  inherit = tf$keras$optimizers$schedules$LearningRateSchedule,
  defs = list(
    
    ###
    `__init__` = function(self, d_model, warmup_steps = 4000L) {
      super()$`__init__`()
      
      self$d_model = d_model
      self$d_model = tf$cast(self$d_model, tf$float32)
      
      self$warmup_steps = warmup_steps
      
      return(NULL)
    },
    
    ###
    `__call__` = function(self, step) {
      arg1 = tf$math$rsqrt(step)
      arg2 = step * (self$warmup_steps ^ (-1.5))
      
      return(tf$math$rsqrt(self$d_model) * tf$math$minimum(arg1, arg2))
    }
  )
)
```

```{r}
learning_rate <- CustomSchedule(d_model)

optimizer <- tf$keras$optimizers$Adam(learning_rate, beta_1 = 0.9, beta_2 = 0.98, epsilon = 1e-9)
```

```{r, fig.width=5}
temp_learning_rate_schedule <- CustomSchedule(d_model)

plot(temp_learning_rate_schedule(tf$range(40000, dtype = tf$float32))$numpy(), xlab = "Train Step", ylab = "Learning Rate", type = "l")
```

## Loss and metrics

```{r}
loss_object <- tf$keras$losses$SparseCategoricalCrossentropy(from_logits = TRUE, reduction = 'none')
```

```{r}
loss_function <- function(real, pred) {
  mask = tf$math$logical_not(tf$math$equal(real, 0L))
  loss_ = loss_object(real, pred)
  
  mask = tf$cast(mask, dtype = loss_$dtype)
  loss_ = loss_ * mask
  
  return(tf$reduce_mean(loss_))
}
```

```{r}
train_loss <- tf$keras$metrics$Mean(name = 'train_loss')
train_accuracy <- tf$keras$metrics$SparseCategoricalAccuracy(name = 'train_accuracy')
```

## Training and checkpointing

```{r}
transformer <- Transformer(
  num_layers, 
  d_model, 
  num_heads, 
  dff,
  input_vocab_size, 
  target_vocab_size, 
  pe_input = input_vocab_size, 
  pe_target = target_vocab_size,
  rate = dropout_rate
)
```


```{r}
create_masks <- function(inp, tar) {
  # Encoder padding mask
  enc_padding_mask <- create_padding_mask(inp)
  
  # Used in the 2nd attention block in the decoder$
  # This padding mask is used to mask the encoder outputs$
  dec_padding_mask <- create_padding_mask(inp)
  
  # Used in the 1st attention block in the decoder$
  # It is used to pad and mask future tokens in the input received by 
  # the decoder$
  look_ahead_mask <- create_look_ahead_mask(tf$shape(tar)[length(tf$shape(tar)$numpy())])
  dec_target_padding_mask <- create_padding_mask(tar)
  combined_mask <- tf$maximum(dec_target_padding_mask, look_ahead_mask)
  
  return(list(enc_padding_mask, combined_mask, dec_padding_mask))
}
```

Create the checkpoint path and the checkpoint manager. This will be used to save checkpoints every n epochs.

```{r}
checkpoint_path = "./checkpoints/train"

ckpt <- tf$train$Checkpoint(transformer = transformer, optimizer = optimizer)

ckpt_manager <- tf$train$CheckpointManager(ckpt, checkpoint_path, max_to_keep = 5)

# if a checkpoint exists, restore the latest checkpoint$
if(!is.null(ckpt_manager$latest_checkpoint)) {
  ckpt$restore(ckpt_manager$latest_checkpoint)
  print('Latest checkpoint restored!!')
}
```

```{r}
EPOCHS = 20
```

```{r}
train_step_signature <- c(
  tf$TensorSpec(shape = c(NULL, NULL), dtype = tf$int64),
  tf$TensorSpec(shape = c(NULL, NULL), dtype = tf$int64)
)

train_step <- function(inp, tar) {
  tar_inp  = tar[ , 1:(dim(tar)[2] - 1)]
  tar_real = tar[ , 2:(dim(tar)[2])]
  
  c(enc_padding_mask, combined_mask, dec_padding_mask) %<-% create_masks(inp, tar_inp)
  
  with(tf$GradientTape() %as% tape, {
    c(predictions, .) %<-% transformer$call(
      inp, 
      tar_inp, 
      TRUE, 
      enc_padding_mask, 
      combined_mask, 
      dec_padding_mask
    )
    
    loss = loss_function(tar_real, predictions)
  })
  
  gradients = tape$gradient(loss, transformer$trainable_variables)    
  optimizer$apply_gradients(transpose(list(gradients, transformer$trainable_variables)))
  
  train_loss(loss)
  train_accuracy(tar_real, predictions)
  
  return(NULL)
}
```

```{r}
for(epoch in seq_len(EPOCHS)) {
  start = Sys.time()
  
  train_loss$reset_states()
  train_accuracy$reset_states()
  
  # inp -> portuguese, tar -> english
  train_dataset_iter <- iterate(train_dataset)
  for(batch in seq_along(train_dataset_iter)) {
    inp <- train_dataset_iter[[batch]]$pt
    tar <- train_dataset_iter[[batch]]$en
    train_step(inp, tar)
    if(batch %% 50L == 0L){
      cat(
        sprintf(
          'Epoch %s Batch %s Loss %.4f Accuracy %.4f\n', 
          epoch , 
          batch, 
          train_loss$result(), 
          train_accuracy$result()
        )
      )
    }
  }
      
  if((epoch) %% 5L == 0L){
    ckpt_save_path = ckpt_manager$save()
    cat(sprintf('Saving checkpoint for epoch %s at %s\n', epoch, ckpt_save_path))
  }
    
  cat(sprintf('Epoch %s Loss %.4f Accuracy %.4f\n', epoch,  train_loss$result(), train_accuracy$result()))

  cat(sprintf('Time taken for 1 epoch: %s secs\n', difftime(Sys.time() , start, units='secs')))
}
```

## Evaluate

```{r}
evaluate <- function(inp_sentence) {
  start_token <- tokenizer_pt$vocab_size
  end_token <- tokenizer_pt$vocab_size + 1L
  
  # inp sentence is portuguese, hence adding the start and end token
  inp_sentence <- as.integer(c(start_token, tokenizer_pt$encode(inp_sentence), end_token))
  encoder_input <- tf$expand_dims(inp_sentence, 0L)
  
  # as the target is english, the first word to the transformer should be the
  # english start token.
  decoder_input <- tokenizer_en$vocab_size
  output <- tf$expand_dims(decoder_input, 0L)
  
  for(i in seq_len(MAX_LENGTH)) {
    c(enc_padding_mask, combined_mask, dec_padding_mask) %<-% create_masks(encoder_input, output)
    
    # predictions.shape == (batch_size, seq_len, vocab_size)
    c(predictions, attention_weights) %<-% transformer$call(encoder_input, 
                                                            output,
                                                            FALSE,
                                                            enc_padding_mask,
                                                            combined_mask,
                                                            dec_padding_mask)
    

    # select the last word from the seq_len dimension
    predictions <- predictions[ ,predictions$shape$as_list()[2], ]  # (batch_size, 1, vocab_size)
    predicted_id <- tf$cast(tf$argmax(predictions, axis = -1L), tf$int32)
        
    # return the result if the predicted_id is equal to the end token
    if(as.integer(predicted_id) == (tokenizer_en$vocab_size + 1L)) {
      output <- if(any(output$shape$as_list() == 1)) tf$squeeze(output, axis = 0) else output
      return(list(output, attention_weights))
    }
    # concatentate the predicted_id to the output which is given to the decoder
    # as its input.
    output <- tf$concat(list(output, predicted_id), axis = -1L)
  }
  
  output <- if(any(output$shape$as_list() == 1)) tf$squeeze(output, axis = 0) else output
  return(list(output, attention_weights))
}

```


```{r}
plot_attention_weights <- function(attention, sentense, result, layer) {
  sentense <- tokenizer_pt$encode(sentense)
  
  attention <- tf$squeeze(attention[[layer]], axis=0)
  
  tokens_pt <- sentense %>% map_chr(~tokenizer_pt$decode(c(.x, 0L)))
  tokens_en <- result[result < tokenizer_en$vocab_size] %>% as.array() %>% map_chr(~tokenizer_en$decode(c(.x, 0L)))
  
  attention_df <- as.array(attention) %>% 
    purrr::array_branch(1) %>% 
    enframe("head", "weights") %>% 
    mutate(head = paste("Head", head)) %>% 
    mutate(weights = map(weights, ~.x[-1,] %>% 
                           as.data.frame.matrix() %>% 
                           mutate(output = str_pad((row_number()), width = 4, pad = 0, side = "left")) %>%
                           gather(-output, key = "input", value = "weight"))) %>% 
    unnest(cols = weights) %>%
    mutate(
      output = factor(output, labels = tokens_en),
      input = factor(input, labels = c("<start>", tokens_pt, "<end>"))
    )
  
  graph <- attention_df %>% 
    ggplot(aes(x = input, y = output, fill = weight)) +
    geom_tile() +
    facet_wrap(~head, scales = "free") +
    scale_fill_viridis_c() +
    scale_x_discrete(position = "top") +
    theme(
        axis.text.x = element_text(angle = 90, hjust = 0, vjust = 0)
    ) 
  
  print(graph)
  return(attention)
}
```

```{r}
translate <- function(sentense, plot = '') {
  c(result, attention_weights) %<-% evaluate(sentense)
  
  predicted_sentence <- tokenizer_en$decode(result[result < tokenizer_en$vocab_size])
  
  
  if(shiny::isTruthy(plot)) {
    plot_attention_weights(attention_weights, sentense, result, plot)
  }
  
  return(list(input = sentense, output = predicted_sentence))
}
```

```{r, fig.height=10}
translate("este é um problema que temos que resolver.", plot='decoder_layer4_block2')
print ("Real translation: this is a problem we have to solve .")
```

